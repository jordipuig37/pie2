---
title: "CheatSheet"
output:
  html_document:
    fig_width: 4
    fig_height: 4
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
```

# Models lineals

### Prèvia
LLibreries que acostumem a incloure encara que no sabem exactament què fan.
```{r}
library(emmeans)
library(car)
library(RcmdrMisc)
library(tables)
```

### Basics
Carregar les dades del fitxer data.csv i plantejar un model.

```{r}
setwd('.')
dades<-read.csv2("./data.csv")
# dades<-read.csv2("~/uni/2n/prob2/exercicis r/comrect.csv")
# Assegurar-se que les columnes (en aquest cas) Any i M són factors
# (poden no carregar-se automàticament com a factors si són números com passa a Any)
dades$Any<-as.factor(dades$Any)
dades$M<-as.factor(dades$M)

# per comprovar-ho:
is.factor(dades$Any)
# plantejar un model
model = lm(formula=Y~X, data=dades)
```

Exemples de fórmules per diferents models:

```{r}
f0 = Y ~ 1 # model null
f1 = Y ~ X # regresió simple
f2 = Y ~ X1 + X2 # model aditiu
f22= Y ~ X + M # model aditiu però una variable és un factor en realitat
f3 = Y ~ X * M # regresió simple amb un factor o model factorial
```


#### Per veure ràpidament les dades:  
__Funció scatterplot per les rectes de regressió__\
*scatterplot(formula(factorial), data)* ploteja la variable resposta vs la variable en una recta per cada factor. Si la fórmula és d'un model aditiu es veu només una recta. Aquí és on hem d'observar linealitat per complir les hipòtesis dels models lineals.


```{r}
scatterplot(Y~X*M,smooth=F, boxplot = F,data=dades)
```

__Les mitjanes per diferents factors__\
*with(data, plotMeans(response, factor1, factor2))* fa la mitjana per cada combinació dels dos factors 1 i 2.

```{r}
with(dades,plotMeans(response=Y,factor1=Any,factor2=M,error.bars="none",level=0.95))
```


__EMMeans__\
EMM (estimated marginal means) calcula les mitjanes marginals per alguns factors especificats a *specs*
Podem veure quins factors són estadísticament diferents (amb un nivell de significació donat) visualment amb pwpp(em) si no estan units per la línia. Tenim funcions interessants com pairs(em) que fan un anàlisis de *emm* per parells. Calcula .

```{r}
dades_emm <- read.csv2("./gmd.csv")
m <- lm(GMD~DOSI,dades_emm)

(emm<-emmeans(m,~DOSI))

pairs(emm)
CLD(emm)
```

La funció *pwpp()* amb el paràmetre *adjust="tukey"* ens fa una gràfica que relaciona cada parell de factors i diu si són estadísticament diferents per un nivell de significació donat en l'eix x.

```{r}
pwpp(emm, adjust="tukey")
```

En aquest cas diríem que donat un nivell de significació del 0.01 són diferents si estan units, per tant D15 i D08, D00 i D15, D00 amb tots menys amb D08...

### Comprovacions

#### Test Anova i Omnibus
Per fer les taules anova utilitzem la funció anova(model). Tenim tipus I, II, III i la més comú i recomenable és el tipus II (Anova()). Ens indica la significació de cada paràmetre (si cada paràmetre sol és igual a zero o no) i l'estadístic de contrast (F value)

```{r}
mod = lm(Y~X*M, dades)
m0d = lm(Y~1, dades)

Anova(mod)
anova(mod,m0d)
```

#### Summary

La funció summary() del model ens dona un resum. Ens dona els paràmetres del model estimats, l'error estàndard, i el t-valor i la significació del paràmetre.

Per la variancia de l'error afegim $sigma^2

```{r}
summary(mod)$sigma^2
summary(mod)
```


#### Errors

__Errors vs Y__\
Els errors els podem veure amb la funció plot i el parametre *which* = 1.
La funció plot té més funcionalitats si el primer paràmetre és el model lineal i *which* = [1,6]:

1. A plot of residuals against fitted values\
2. A normal Q-Q plot\
3. A Scale-Location plot of sqrt(| residuals |) against fitted values\
4. A plot of Cook's distances versus row labels\
5. A plot of residuals against leverages\
6. A plot of Cook's distances against leverage/(1-leverage)\

Ara veiem el plot dels residus. Recorda que s'ha de veure una distribució uniforme sobre el pla. Si es veu alguna forma d'embut o parabòlica cal aplicar transformacions. Aquesta distribució uniforme verifica la hipòtesis de l'independència dels errors.

```{r out.width = '50%'}
dd <- read.csv2("./col.csv")
mod<-lm(C~P,dd)
# plot(mod,which=1)
plot(predict(mod),resid(mod),main="Residuals vs Predits")
# línia al 0 per veure el centre
abline(h=0,lty=2)
```



__Errors studentizats__
Aqui cal veure que no hi ha valors per sobre del 3 o més avall del -3, y a més que es pot observar normalitat del valors.
```{r}
plot(rstudent(mod),main="Residuals studentitzats")
abline(h=c(-3,-2,0,2,3),lty=2)
```


__Valors influents__\
Els DFFITS són una mesura similar a la distància de Cook. Ens indica si hi ha algun residu molt lluny.

```{r}
p<-2
n<-dim(dd)[1]
plot(dffits(mod),main="DFFITS")
# Les línies que posem son als valors {-3, -2, 0, 2, 3} però multiplicades per un factor de squrt(p/n)
abline(h=c(-3,-2,0,2,3)*sqrt(p/n),lty=2)
```


__QQ-plot dels errors__\
Per fer la segona comprovació dels errors fem l'anomenat qq-plot dels errors. Aquí hem  d'observar linealitat.

```{r}
plot(mod, which=2)
```

# GLM

Aqui es donde comienza la fiesta. Primero de todo, las familias:

a. Normal
b. Binomial
c. Poisson
d. Gamma
e. Inversa Gaussiana
f. Otras

Si te olvidas de como tienes que escribirlas solo ve a `?family`.
Segundo, las funciones link se especifican justo al lado y entre paréntesis de la familia. Ej.: `family=binomial(link=probit)`. Para hacer un ejemplo completo usaré uno de los últimos ejercicios:
```{r}
dd <- data.frame(time=c(16,16,16,24,24,24),
                  dose=c(0, 0.45, 0.75, 0, 0.45, 0.75),
                  tumor=c(1,3,7, 20,98,118),
                  total=c(205,304,193, 762,888,587))
dd$time <- as.factor(dd$time)

m <- glm(tumor/total~time*dose, data=dd, family=binomial, weights=total)
anova(m, test="Chisq")
summary(m)
```

En general se suele usar el test Chi cuadrado para hacer el anova, aunque también puede aparecer el F de fisher, depende de la familia, por suerte R te suele avisar si lo pones mal. Por lo demás, el análisis es como en los modelos lineales.

__Residuos__
Hay de dos tipos, devianza y pearson. Se puede utilizar para calcular el parámetro de dispersión que en el caso de la Poisson y la binomial debe ser cercano a 1.
```{r}
resid(m, ty="pearson")
resid(m, ty="deviance")

PRS <- sum(resid(m, ty="pearson"))
c("Par.disp"=PRS/m$df.res, "p-valor"=2*min(pchisq(PRS,m$df.res),1-pchisq(PRS,m$df.res)))
```
En este caso sale infradispersión, si sale sobredispersión entonces hay que preocuparse mal y o bien los datos no siguen la distribución esperada o el modelo está mal. También se pueden hacer los análisis de siempre.
```{r}
plot(m, 1)
plot(rstudent(m))
abline(h=c(-2,0,2), lty=2)
```


___Predicciones___
```{r}
Dose <- seq(0, 1, .01)
plot(tumor/total~(dose), data=dd)
lines(predict(m, data.frame(time=as.factor(rep(16, 101)), dose=Dose), ty="response")~(Dose), col="red")
lines(predict(m, data.frame(time=as.factor(rep(24, 101)), dose=Dose), ty="response")~(Dose), col="green")
abline(h=c(0,1), col="grey")
```
